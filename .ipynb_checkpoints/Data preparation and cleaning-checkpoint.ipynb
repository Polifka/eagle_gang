{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data_preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import all relevant libraries\n",
    "\n",
    "* install haversine ($ pip install haversine ; https://pypi.org/project/haversine/ )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been provided with an already pre-processed dataset of bike sharing rentals for\n",
    "the cities of Bremen and DÃ¼sseldorf over a time period of 5 months. Before cleaning the\n",
    "data in a second step, we decided first to add some time- and distance based measurements.\n",
    "For further information take a look into the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from haversine import haversine, Unit\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"GnBu_d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define reading functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trip_data_readin (city):\n",
    "    trip_data = pd.read_csv(\"Project_Data/Trip_Data/\"+city+\".csv\", encoding = \"ISO-8859-1\")\n",
    "    trip_data = trip_data_data_prep(trip_data)\n",
    "    trip_data = merge_trip_data_with_weather_data(trip_data, city)\n",
    "    return trip_data\n",
    "\n",
    "\n",
    "def trip_data_data_prep(trip_data):\n",
    "    trip_data[\"datetime_start\"] = pd.to_datetime(trip_data['day'] + ' ' + trip_data['time'])\n",
    "    trip_data[\"trip_duration\"] = pd.to_timedelta(trip_data[\"trip_duration\"])\n",
    "    trip_data[\"datetime_end\"] = trip_data[\"datetime_start\"] + trip_data[\"trip_duration\"]\n",
    "    trip_data[\"weekday\"] = pd.to_datetime(trip_data[\"datetime_start\"]).dt.weekday\n",
    "    trip_data[\"month\"] = trip_data[\"datetime_start\"].dt.month\n",
    "    trip_data[\"hour\" ] = trip_data[\"datetime_start\"].dt.hour\n",
    "    trip_data[\"week\" ] = trip_data[\"datetime_start\"].dt.isocalendar().week\n",
    "    \n",
    "    trip_data = estimate_fleetsize(trip_data,\"week\")\n",
    "    trip_data = estimate_fleetsize(trip_data,\"day\")\n",
    "    trip_data = estimate_fleetsize(trip_data,\"month\")\n",
    "    \n",
    "    trip_data = distance_between_coordinates (trip_data)    \n",
    "    trip_data = cleaning(trip_data)\n",
    "    return trip_data\n",
    "\n",
    "def distance_between_coordinates (trip_data):\n",
    "    trip_data[\"distance\"] = trip_data.apply(lambda row: haversine((row[\"orig_lat\"], row[\"orig_lng\"]),(row[\"dest_lat\"], row[\"dest_lng\"]),Unit.KILOMETERS), axis=1) \n",
    "    return trip_data\n",
    "\n",
    "def estimate_fleetsize(trip_data, time_resolution):\n",
    "    temp = pd.DataFrame(trip_data.groupby(time_resolution)[\"b_number\"].nunique())\n",
    "    temp = temp.rename(columns={\"b_number\": \"fleetsize_\"+time_resolution+\"ly\"})\n",
    "    trip_data =pd.merge(trip_data, temp , on=time_resolution, how='left')\n",
    "    return trip_data\n",
    "\n",
    "def merge_trip_data_with_weather_data (trip_data, city):\n",
    "    trip_data.set_index(pd.DatetimeIndex(trip_data[\"datetime_start\"]),inplace=True)\n",
    "    weather = read_DWD_data (city)\n",
    "    trip_data[\"rounded_time_hourly\"] = trip_data[\"datetime_start\"].dt.round(\"H\")\n",
    "    combined = pd.merge(trip_data, weather , on=\"rounded_time_hourly\", how='left')\n",
    "    combined[\"wind\"] = combined['wind'].fillna(method=\"ffill\")\n",
    "    combined[\"rain\"] = combined['rain'].fillna(method=\"ffill\")\n",
    "    combined[\"temp\"] = combined['temp'].fillna(method=\"ffill\")\n",
    "    return combined\n",
    "\n",
    "\n",
    "def read_DWD_data (city):\n",
    "    \n",
    "    temp_data = pd.read_csv(\"Project_Data/Weather_Data/\"+city+\"/\"+\"data_TT_TU_MN009.csv\", encoding = \"ISO-8859-1\")\n",
    "    temp_data =temp_data.rename(columns={\"Zeitstempel\": \"rounded_time_hourly\"})\n",
    "    temp_data.set_index((pd.to_datetime(temp_data['rounded_time_hourly'].astype(str), format='%Y%m%d%H%M') ),inplace=True)\n",
    "    temp_data=temp_data.drop(['Produkt_Code', 'SDO_ID','SDO_ID','Qualitaet_Niveau','Qualitaet_Byte','rounded_time_hourly'], axis=1)\n",
    "    temp_data.columns = ['temp']\n",
    "\n",
    "\n",
    "    wind_data = pd.read_csv(\"Project_Data/Weather_Data/\"+city+\"/\"+\"data_F_MN003.csv\", encoding = \"ISO-8859-1\")\n",
    "    wind_data =wind_data.rename(columns={\"Zeitstempel\": \"rounded_time_hourly\"})\n",
    "    wind_data.set_index((pd.to_datetime(wind_data['rounded_time_hourly'].astype(str), format='%Y%m%d%H%M') ),inplace=True)\n",
    "    wind_data = wind_data.drop(['Produkt_Code', 'SDO_ID','SDO_ID','Qualitaet_Niveau','Qualitaet_Byte','rounded_time_hourly'], axis=1)\n",
    "    wind_data.columns = ['wind']\n",
    "\n",
    "    \n",
    "    rain_data = pd.read_csv(\"Project_Data/Weather_Data/\"+city+\"/\"+\"data_R1_MN008.csv\", encoding = \"ISO-8859-1\")\n",
    "    rain_data =rain_data.rename(columns={\"Zeitstempel\": \"rounded_time_hourly\"})\n",
    "    rain_data.set_index((pd.to_datetime(rain_data['rounded_time_hourly'].astype(str), format='%Y%m%d%H%M') ),inplace=True)\n",
    "    rain_data = rain_data.drop(['Produkt_Code', 'SDO_ID','SDO_ID','Qualitaet_Niveau','Qualitaet_Byte','rounded_time_hourly'], axis=1)\n",
    "    rain_data.columns = ['rain']\n",
    "    \n",
    "    \n",
    "    weather = pd.merge(temp_data, wind_data , on=\"rounded_time_hourly\", how='left')\n",
    "    weather = pd.merge(weather, rain_data , on=\"rounded_time_hourly\", how='left')\n",
    "    return weather\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting trips with avg. speed over 25km/h\n",
    "def cleaning (trip_data):\n",
    "    trip_data[\"trip_duration_hours\"] = trip_data[\"trip_duration\"].dt.total_seconds()/3600\n",
    "    trip_data[\"avg_speed\"] = trip_data[\"distance\"]/trip_data[\"trip_duration_hours\"]\n",
    "    trip_data.drop(trip_data[trip_data[\"avg_speed\"]>25].index, axis=0, inplace=True)\n",
    "    return trip_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Create combined Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export (city_name):\n",
    "    data_set = trip_data_readin(city_name)\n",
    "    data_set.to_csv(\"Project_Data/Combined_Data/\"+city_name+\".csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute only in case of new data updates #\n",
    "\n",
    "# export (\"duesseldorf\")\n",
    "# export (\"bremen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = trip_data_readin(\"bremen\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fleet Size:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section deals with the calculation of the fleet size of the respective cities, which will be used as a basis for the calculation of other key performance indices (KPI). Since the fleet size is not covered by the data, we approximate the fleet size based on the number of bikes in a given period. To assess this period, the following fleet sizes were first calculated:\n",
    "\n",
    "1. **Fleet size per week:** Assuming that a bike that does not appear in the list of trips for a week is no longer part of the fleet.\n",
    "2. **Fleet size per month:** Assuming that the fleet only includes bikes that have been driven within one month.\n",
    "3. **Fleet size per day:** Based on the assumption that bicycles that have not been used for a day are no longer part of the fleet.\n",
    "\n",
    "### Read data\n",
    "\n",
    "Reading the data per city:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(city_name):\n",
    "    trip_data = pd.read_csv(\"Project_Data/Combined_Data/\"+city_name+\".csv\", encoding = \"ISO-8859-1\")\n",
    "    trip_data[\"trip_duration\"] = pd.to_timedelta(trip_data[\"trip_duration\"])\n",
    "    trip_data[\"datetime_start\"] = pd.to_datetime(trip_data[\"datetime_start\"])\n",
    "    trip_data[\"datetime_end\"] = pd.to_datetime(trip_data[\"datetime_end\"])\n",
    "    trip_data[\"day\"] = pd.to_datetime(trip_data[\"day\"])\n",
    "\n",
    "\n",
    "    return trip_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate fleet sizes\n",
    "\n",
    "Calculate and plot fleet sizes based on time resolution and fleet data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_fleet_size (fleet, timeresolution):\n",
    "    fleet[\"day\"] = pd.to_datetime(fleet[\"day\"],format='%Y%m%d')\n",
    "    fleet[\"week\"] = fleet[\"day\"].dt.isocalendar().week\n",
    "\n",
    "\n",
    "    first = fleet[\"day\"].iloc[0]\n",
    "    last = fleet[\"day\"].iloc[-1]\n",
    "    i = (last-first)/np.timedelta64(1,'D')\n",
    "    test = first + pd.to_timedelta(np.arange(int(i)+1), 'D')\n",
    "    plot = pd.DataFrame(test)\n",
    "    plot = plot.set_index(test)\n",
    "    plot = pd.DataFrame((fleet.groupby(timeresolution)[\"b_number\"].nunique()))\n",
    "    return plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
