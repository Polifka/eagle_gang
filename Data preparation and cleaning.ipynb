{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data_preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import all relevant libraries\n",
    "\n",
    "* install haversine ($ pip install haversine ; https://pypi.org/project/haversine/ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from haversine import haversine, Unit\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"GnBu_d\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define readin functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trip_data_readin (city):\n",
    "    trip_data = pd.read_csv(\"Project_Data/Trip_Data/\"+city+\".csv\", encoding = \"ISO-8859-1\")\n",
    "    trip_data = trip_data_data_prep(trip_data)\n",
    "    trip_data = merge_trip_data_with_weather_data(trip_data, city)\n",
    "    return trip_data\n",
    "\n",
    "\n",
    "def trip_data_data_prep(trip_data):\n",
    "    trip_data[\"datetime_start\"] = pd.to_datetime(trip_data['day'] + ' ' + trip_data['time'])\n",
    "    trip_data[\"trip_duration\"] = pd.to_timedelta(trip_data[\"trip_duration\"])\n",
    "    trip_data[\"datetime_end\"] = trip_data[\"datetime_start\"] + trip_data[\"trip_duration\"]\n",
    "    trip_data[\"weekday\"] = pd.to_datetime(trip_data[\"datetime_start\"]).dt.weekday\n",
    "    trip_data[\"month\"] = trip_data[\"datetime_start\"].dt.month\n",
    "    trip_data[\"hour\" ] = trip_data[\"datetime_start\"].dt.hour\n",
    "    trip_data[\"week\"] = trip_data[\"datetime_start\"].dt.isocalendar().week\n",
    "\n",
    "\n",
    "    \n",
    "    trip_data = distance_between_coordinates (trip_data)    \n",
    "    trip_data = cleaning(trip_data)\n",
    "    return trip_data\n",
    "\n",
    "def distance_between_coordinates (trip_data):\n",
    "    trip_data[\"distance\"] = trip_data.apply(lambda row: haversine((row[\"orig_lat\"], row[\"orig_lng\"]),(row[\"dest_lat\"], row[\"dest_lng\"]),Unit.KILOMETERS), axis=1) \n",
    "    return trip_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def merge_trip_data_with_weather_data (trip_data, city):\n",
    "    trip_data.set_index(pd.DatetimeIndex(trip_data[\"datetime_start\"]),inplace=True)\n",
    "    weather = read_DWD_data (city)\n",
    "    trip_data[\"rounded_time_hourly\"] = trip_data[\"datetime_start\"].dt.round(\"H\")\n",
    "    combined = pd.merge(trip_data, weather , on=\"rounded_time_hourly\", how='left')\n",
    "    combined[\"wind\"] = combined['wind'].fillna(method=\"ffill\")\n",
    "    combined[\"rain\"] = combined['rain'].fillna(method=\"ffill\")\n",
    "    combined[\"temp\"] = combined['temp'].fillna(method=\"ffill\")\n",
    "    return combined\n",
    "\n",
    "\n",
    "def read_DWD_data (city):\n",
    "    \n",
    "    temp_data = pd.read_csv(\"Project_Data/Weather_Data/\"+city+\"/\"+\"data_TT_TU_MN009.csv\", encoding = \"ISO-8859-1\")\n",
    "    temp_data =temp_data.rename(columns={\"Zeitstempel\": \"rounded_time_hourly\"})\n",
    "    temp_data.set_index((pd.to_datetime(temp_data['rounded_time_hourly'].astype(str), format='%Y%m%d%H%M') ),inplace=True)\n",
    "    temp_data=temp_data.drop(['Produkt_Code', 'SDO_ID','SDO_ID','Qualitaet_Niveau','Qualitaet_Byte','rounded_time_hourly'], axis=1)\n",
    "    temp_data.columns = ['temp']\n",
    "\n",
    "\n",
    "    wind_data = pd.read_csv(\"Project_Data/Weather_Data/\"+city+\"/\"+\"data_F_MN003.csv\", encoding = \"ISO-8859-1\")\n",
    "    wind_data =wind_data.rename(columns={\"Zeitstempel\": \"rounded_time_hourly\"})\n",
    "    wind_data.set_index((pd.to_datetime(wind_data['rounded_time_hourly'].astype(str), format='%Y%m%d%H%M') ),inplace=True)\n",
    "    wind_data = wind_data.drop(['Produkt_Code', 'SDO_ID','SDO_ID','Qualitaet_Niveau','Qualitaet_Byte','rounded_time_hourly'], axis=1)\n",
    "    wind_data.columns = ['wind']\n",
    "\n",
    "    \n",
    "    rain_data = pd.read_csv(\"Project_Data/Weather_Data/\"+city+\"/\"+\"data_R1_MN008.csv\", encoding = \"ISO-8859-1\")\n",
    "    rain_data =rain_data.rename(columns={\"Zeitstempel\": \"rounded_time_hourly\"})\n",
    "    rain_data.set_index((pd.to_datetime(rain_data['rounded_time_hourly'].astype(str), format='%Y%m%d%H%M') ),inplace=True)\n",
    "    rain_data = rain_data.drop(['Produkt_Code', 'SDO_ID','SDO_ID','Qualitaet_Niveau','Qualitaet_Byte','rounded_time_hourly'], axis=1)\n",
    "    rain_data.columns = ['rain']\n",
    "    \n",
    "    \n",
    "    weather = pd.merge(temp_data, wind_data , on=\"rounded_time_hourly\", how='left')\n",
    "    weather = pd.merge(weather, rain_data , on=\"rounded_time_hourly\", how='left')\n",
    "    return weather\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting trips with avg. speed over 25km/h\n",
    "def cleaning (trip_data):\n",
    "    trip_data[\"trip_duration_hours\"] = trip_data[\"trip_duration\"].dt.total_seconds()/3600\n",
    "    trip_data[\"avg_speed\"] = trip_data[\"distance\"]/trip_data[\"trip_duration_hours\"]\n",
    "    trip_data.drop(trip_data[trip_data[\"avg_speed\"]>25].index, axis=0, inplace=True)\n",
    "    return trip_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Create combined Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export (city_name):\n",
    "    data_set = trip_data_readin(city_name)\n",
    "    data_set.to_csv(\"Project_Data/Combined_Data/\"+city_name+\".csv\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute only in case of new data updates #\n",
    "\n",
    "export (\"duesseldorf\")\n",
    "export (\"bremen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = trip_data_readin(\"bremen\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 57894 entries, 0 to 57893\n",
      "Data columns (total 21 columns):\n",
      " #   Column               Non-Null Count  Dtype          \n",
      "---  ------               --------------  -----          \n",
      " 0   day                  57894 non-null  object         \n",
      " 1   time                 57894 non-null  object         \n",
      " 2   b_number             57894 non-null  int64          \n",
      " 3   city                 57894 non-null  object         \n",
      " 4   trip_duration        57894 non-null  timedelta64[ns]\n",
      " 5   orig_lat             57894 non-null  float64        \n",
      " 6   orig_lng             57894 non-null  float64        \n",
      " 7   dest_lat             57894 non-null  float64        \n",
      " 8   dest_lng             57894 non-null  float64        \n",
      " 9   datetime_start       57894 non-null  datetime64[ns] \n",
      " 10  datetime_end         57894 non-null  datetime64[ns] \n",
      " 11  weekday              57894 non-null  int64          \n",
      " 12  month                57894 non-null  int64          \n",
      " 13  hour                 57894 non-null  int64          \n",
      " 14  distance             57894 non-null  float64        \n",
      " 15  trip_duration_hours  57894 non-null  float64        \n",
      " 16  avg_speed            57894 non-null  float64        \n",
      " 17  rounded_time_hourly  57894 non-null  datetime64[ns] \n",
      " 18  temp                 57894 non-null  float64        \n",
      " 19  wind                 44505 non-null  float64        \n",
      " 20  rain                 57894 non-null  float64        \n",
      "dtypes: datetime64[ns](3), float64(10), int64(4), object(3), timedelta64[ns](1)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fb793ac0be0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
